{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada5aa2d-388d-4a00-b168-dd76c39cf0d2",
   "metadata": {},
   "source": [
    "# Regridding SPC LSRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0467a098-453d-44f4-8e3a-25faa5eefbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xoak\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from shapely.ops import nearest_points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901aefd4-a8f3-4d20-aefd-6c19d57dece6",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b71b56-fec8-48c5-ba02-d4b90eca704d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15589/2709948194.py:4: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_wind = pd.read_csv('1955-2022_wind.csv')\n"
     ]
    }
   ],
   "source": [
    "#load the tornado, hail, and wind dataframes\n",
    "df_tor = gpd.read_file('1950-2022_torn.csv')\n",
    "df_hail = pd.read_csv('1955-2022_hail.csv')\n",
    "df_wind = pd.read_csv('1955-2022_wind.csv')\n",
    "\n",
    "#convert times to pandas datetimes\n",
    "df_tor['date'] = pd.to_datetime(df_tor['date'])\n",
    "df_hail['date'] = pd.to_datetime(df_hail['date'])\n",
    "df_wind['date'] = pd.to_datetime(df_wind['date'])\n",
    "\n",
    "#subset the dataframes based on the timerange\n",
    "df_tor = df_tor[(df_tor['date'] >= '1990-10-01') & (df_tor['date'] <= '2005-09-30')]\n",
    "df_wind = df_wind[(df_wind['date'] >= '1990-10-01') & (df_wind['date'] <= '2005-09-30')]\n",
    "df_hail = df_hail[(df_hail['date'] >= '1990-10-01') & (df_hail['date'] <= '2005-09-30')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485f33e9-5052-4cf3-96c5-8f6821bc4c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the geometry to the files\n",
    "df_tor['geometry'] = gpd.points_from_xy(df_tor.slon, df_tor.slat)\n",
    "df_hail['geometry'] = gpd.points_from_xy(df_hail.slon, df_hail.slat)\n",
    "df_wind['geometry'] = gpd.points_from_xy(df_wind.slon, df_wind.slat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d51cb7-87af-4ed6-baea-c869dc66758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open dummy xarray dataset\n",
    "ds = xr.open_dataset('/home/scratch/WRF_BCC/severe_weather/UP_HELI_MAX/historical/1990-1991/UP_HELI_MAX_historical-1990-1991_1990-10-01.nc')\n",
    "ds = ds.sel(Time ='1990-10-01T00:00:00.000000000')\n",
    "ds_copy = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2664f9b9-5db1-4b1f-be76-b8c673448655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load and coarsen the geog file\n",
    "geog = xr.open_dataset(\"/home/scratch/WRF_BCC/geography/geo_em.d01.nc\")\n",
    "geog = geog[['CLAT', 'CLONG']].coarsen(south_north=20, west_east=20, boundary='trim').mean()\n",
    "\n",
    "#coarsen dummy xarray file and merge the two files togther\n",
    "ds = ds.coarsen(south_north=20, west_east=20, boundary='trim').sum()\n",
    "ds = xr.merge([ds, geog.squeeze()])\n",
    "ds = ds.rename({\"CLONG\": 'lon', 'CLAT': 'lat'})\n",
    "\n",
    "#restructure the new dataset\n",
    "ds = ds.assign_coords({'x': ds.west_east, 'y': ds.south_north})\n",
    "ds = ds.assign_coords({'lon': ds.lon, 'lat': ds.lat})\n",
    "ds.xoak.set_index(['lat', 'lon'], 'sklearn_geo_balltree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9393cec-ec86-465f-ab45-70621a67b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the WRF dataframe\n",
    "#flatten the values of the lat/long\n",
    "df_wrf = gpd.GeoDataFrame(geometry=gpd.points_from_xy(ds.lon.values.flatten(), ds.lat.values.flatten()))\n",
    "df_wrf['lat'] = ds.lat.values.flatten()\n",
    "df_wrf['lon'] = ds.lon.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc555ab-1459-43cd-a540-3d306bc49ad4",
   "metadata": {},
   "source": [
    "### Nearest Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53bb8838-f1b5-42dd-b96b-314738fe3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change df variable names\n",
    "gpd1 = df_tor\n",
    "gpd2 = df_wrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f47820ec-4ade-4310-b6d9-4a6bcf6b908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defintion to find the nearest point to a point \n",
    "pts3 = gpd2.geometry.unary_union\n",
    "\n",
    "def near(point, pts=pts3):\n",
    "    \n",
    "    # find the nearest point and return the corresponding Place value\n",
    "    nearest = gpd2.geometry == nearest_points(point, pts)[1]\n",
    "    \n",
    "    return gpd2[nearest].lat, gpd2[nearest].lon\n",
    "\n",
    "gpd1['Nearest'] = gpd1.apply(lambda row: near(row.geometry), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80e240aa-14bc-48fe-8b29-ed2cd57d2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save off file\n",
    "gpd1.to_csv(f'/home/scratch/jcorner1/syn_sev/dataframes/SPC_LSRs_regridded_tor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39413235-3867-43d2-9235-380bfaf4f50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyEAE]",
   "language": "python",
   "name": "conda-env-pyEAE-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
