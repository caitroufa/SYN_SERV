{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2c9ead6-7f31-475f-a6e5-d67cc9652c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cab8a9a-5e74-4f7a-a46d-473cdecbdf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables and file paths\n",
    "paths = {\n",
    "    \"HIST\": '/home/scratch/jcorner1/syn_sev/dataframes/HIST_UVV_[21]*_*.csv',\n",
    "    \"EOC_8p5\": '/home/scratch/jcorner1/syn_sev/dataframes/EOC8p5_UVV*.csv',\n",
    "    \"MC_8p5\": '/home/scratch/jcorner1/syn_sev/dataframes/MC8p5_UVV*.csv',\n",
    "    \"EOC_4p5\": '/home/scratch/jcorner1/syn_sev/dataframes/EOC4p5_UVV*.csv',\n",
    "    \"MC_4p5\": '/home/scratch/jcorner1/syn_sev/dataframes/MC4p5_UVV*.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df133ee8-9bc0-45b5-b42c-ba25aaf9c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to preprocess data\n",
    "def preprocess_and_analyze_data(path):\n",
    "    data_frames = [pd.read_csv(file) for file in glob.glob(path)]\n",
    "    data = pd.concat(data_frames)\n",
    "    \n",
    "    # apply thresholds: UVV >= 25 m2s2 and Z >= 40 dbz\n",
    "    filtered_data = data[(data['UVV'] >= 25) & (data['DBZ'] >= 40)]\n",
    "    \n",
    "    filtered_data['Year'] = pd.to_datetime(filtered_data['Time']).dt.year\n",
    "    \n",
    "    # group by year and count occurrences\n",
    "    yearly_counts = filtered_data.groupby('Year').size()\n",
    "    return yearly_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc256fa-6a91-4392-a35f-a5bceb510c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_65428/999895536.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['Year'] = pd.to_datetime(filtered_data['Time']).dt.year\n",
      "/tmp/ipykernel_65428/999895536.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['Year'] = pd.to_datetime(filtered_data['Time']).dt.year\n",
      "/tmp/ipykernel_65428/999895536.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['Year'] = pd.to_datetime(filtered_data['Time']).dt.year\n",
      "/tmp/ipykernel_65428/999895536.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['Year'] = pd.to_datetime(filtered_data['Time']).dt.year\n",
      "/tmp/ipykernel_65428/999895536.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['Year'] = pd.to_datetime(filtered_data['Time']).dt.year\n"
     ]
    }
   ],
   "source": [
    "# calc yearly mean counts for each epoch\n",
    "yearly_counts = {}\n",
    "for epoch, path in paths.items():\n",
    "    yearly_counts[epoch] = preprocess_and_analyze_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12badb28-ec66-4017-88c6-c9a9eec27fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIST:\n",
      "  Mean: 9529.9375\n",
      "  Median: 9902.5\n",
      "  Std Dev: 3552.9585506307276\n",
      "EOC_8p5:\n",
      "  Mean: 17905.75\n",
      "  Median: 19474.5\n",
      "  Std Dev: 5641.2554453773855\n",
      "MC_8p5:\n",
      "  Mean: 12677.375\n",
      "  Median: 13621.5\n",
      "  Std Dev: 4834.234594707487\n",
      "EOC_4p5:\n",
      "  Mean: 13322.25\n",
      "  Median: 13990.0\n",
      "  Std Dev: 5228.398193200922\n",
      "MC_4p5:\n",
      "  Mean: 12112.375\n",
      "  Median: 11727.0\n",
      "  Std Dev: 4607.059827048049\n"
     ]
    }
   ],
   "source": [
    "# calc climatological mean, median, and standard deviation for each epoch\n",
    "climatological_mean = {}\n",
    "climatological_median = {}\n",
    "climo_std_dev = {}\n",
    "\n",
    "for epoch, counts in yearly_counts.items():\n",
    "    climatological_mean[epoch] = counts.mean()\n",
    "    climatological_median[epoch] = counts.median()\n",
    "    climo_std_dev[epoch] = np.std(counts, ddof=1)  # sample standard deviation\n",
    "\n",
    "# print results for each epoch\n",
    "for epoch in paths:\n",
    "    print(f\"{epoch}:\")\n",
    "    print(f\"  Mean: {climatological_mean[epoch]}\")\n",
    "    print(f\"  Median: {climatological_median[epoch]}\")\n",
    "    print(f\"  Std Dev: {climo_std_dev[epoch]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035fb7d4-8aa4-4cea-bd89-48b41f4e408b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative change mean for EOC_8p5: 87.9%\n",
      "Relative change median for EOC_8p5: 96.7%\n",
      "Relative change mean for MC_8p5: 33.0%\n",
      "Relative change median for MC_8p5: 37.6%\n",
      "Relative change mean for EOC_4p5: 39.8%\n",
      "Relative change median for EOC_4p5: 41.3%\n",
      "Relative change mean for MC_4p5: 27.1%\n",
      "Relative change median for MC_4p5: 18.4%\n"
     ]
    }
   ],
   "source": [
    "# calc relative change in means and medians from HIST\n",
    "relative_change_mean = {}\n",
    "relative_change_median = {}\n",
    "\n",
    "for epoch in paths:\n",
    "    if epoch != 'HIST':  # exclude HIST from comparison with itself\n",
    "        relative_change_mean[epoch] = ((climatological_mean[epoch] - climatological_mean['HIST']) / climatological_mean['HIST']) * 100\n",
    "        relative_change_median[epoch] = ((climatological_median[epoch] - climatological_median['HIST']) / climatological_median['HIST']) * 100\n",
    "\n",
    "# print rel chg percent for each future epoch vs HIST\n",
    "for epoch in relative_change_mean:\n",
    "    print(f\"Relative change mean for {epoch}: {relative_change_mean[epoch]:.1f}%\")\n",
    "    print(f\"Relative change median for {epoch}: {relative_change_median[epoch]:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51befac1-8496-4770-9e1f-80c2497c04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bootstrapping function to calc p-value and confidence interval\n",
    "def bootstrap_p_value(data1, data2, num_bootstrap=10000):\n",
    "    observed_diff = np.mean(data2) - np.mean(data1)\n",
    "    \n",
    "    combined_data = np.concatenate([data1, data2])\n",
    "    bootstrap_diffs = []\n",
    "    \n",
    "    for _ in range(num_bootstrap):\n",
    "        boot_data1 = resample(combined_data, n_samples=len(data1), replace=True)\n",
    "        boot_data2 = resample(combined_data, n_samples=len(data2), replace=True)\n",
    "        bootstrap_diffs.append(np.mean(boot_data2) - np.mean(boot_data1))\n",
    "    \n",
    "    # calc p-value: proportion of bootstrap differences as extreme as observed\n",
    "    bootstrap_diffs = np.array(bootstrap_diffs)\n",
    "    p_value = np.mean(np.abs(bootstrap_diffs) >= np.abs(observed_diff))\n",
    "    \n",
    "    # 95% confidence interval for the difference in means\n",
    "    conf_interval = np.percentile(bootstrap_diffs, [2.5, 97.5])\n",
    "    \n",
    "    return p_value, conf_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5017e8f7-7c45-4cd0-834c-635854973c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap p-value for EOC_8p5 vs HIST: 0.0002\n",
      "95% confidence interval for mean difference: [-4246.7140625  4360.9453125]\n",
      "Bootstrap p-value for MC_8p5 vs HIST: 0.0392\n",
      "95% confidence interval for mean difference: [-3030.3765625  2975.9984375]\n",
      "Bootstrap p-value for EOC_4p5 vs HIST: 0.0216\n",
      "95% confidence interval for mean difference: [-3243.9375     3256.6296875]\n",
      "Bootstrap p-value for MC_4p5 vs HIST: 0.08\n",
      "95% confidence interval for mean difference: [-2876.7     2905.2625]\n"
     ]
    }
   ],
   "source": [
    "# compare HIST vs future epochs using bootstrapping\n",
    "for epoch in paths:\n",
    "    if epoch != 'HIST':\n",
    "        p_val, conf_int = bootstrap_p_value(yearly_counts['HIST'], yearly_counts[epoch])\n",
    "        print(f\"Bootstrap p-value for {epoch} vs HIST: {p_val}\")\n",
    "        print(f\"95% confidence interval for mean difference: {conf_int}\")\n",
    "        \n",
    "# note that i don't believe bootstrapping is appropriate given the small sample size\n",
    "# employing mann whitney instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d004b70-e206-4931-94a6-17b2e4573a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for mann-whitney u test\n",
    "def mann_whitney_test(epoch1_counts, epoch2_counts, epoch1_name, epoch2_name):\n",
    "    stat, p_value = mannwhitneyu(epoch1_counts, epoch2_counts, alternative='two-sided')\n",
    "    print(f'Mann-Whitney U test p-value for {epoch1_name} vs {epoch2_name}: {p_value}')\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d41a9bb-e090-43c3-9d1b-0ccb00406ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mann-Whitney U test p-value for EOC_8p5 vs HIST: 5.08775595038961e-05\n",
      "Mann-Whitney U test p-value for MC_8p5 vs HIST: 0.02259704208824878\n",
      "Mann-Whitney U test p-value for EOC_4p5 vs HIST: 0.01095904665573683\n",
      "Mann-Whitney U test p-value for MC_4p5 vs HIST: 0.03022625498203607\n"
     ]
    }
   ],
   "source": [
    "# calc p-values w/ mann whit\n",
    "p_values = {}\n",
    "\n",
    "for epoch in ['EOC_8p5', 'MC_8p5', 'EOC_4p5', 'MC_4p5']:\n",
    "    p_values[epoch] = mann_whitney_test(yearly_counts[epoch], yearly_counts['HIST'], epoch, 'HIST')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyEAE]",
   "language": "python",
   "name": "conda-env-pyEAE-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
