{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f13e8b6-23e3-44a7-a14b-7ecac57277ac",
   "metadata": {},
   "source": [
    "# Thresholding Variables and Dataframe Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83636772-e348-4047-978d-ddf8337d00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import xoak\n",
    "import geopandas as gpd\n",
    "import regionmask\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7801f69-cf2c-468a-8bb6-08599704d713",
   "metadata": {},
   "source": [
    "### Opening Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd6b384f-1543-4fe3-a8ba-0d3cee2cd445",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find directories with the WRF-BCC data\n",
    "uh_dirts = glob.glob('/home/scratch/WRF_BCC/severe_weather/UP_HELI_MAX/historical/*')\n",
    "uh_dirts.sort()\n",
    "uh_dirts = uh_dirts[:-1]\n",
    "\n",
    "ref_dirts = glob.glob('/home/scratch/WRF_BCC/reflectivity/REFD/historical/*')\n",
    "ref_dirts.sort()\n",
    "ref_dirts = ref_dirts[:]\n",
    "\n",
    "uvv_dirts = glob.glob('/home/scratch/WRF_BCC/severe_weather/W_UP_MAX/historical/*')\n",
    "uvv_dirts.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd3b7d-2a00-43f5-9fdf-5c216ad1a9d8",
   "metadata": {},
   "source": [
    "### Mask the CONUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082389f5-b42f-4a94-81ce-85a8e2aabf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the WRF-BCC geog and a random refc dummy file\n",
    "geog = xr.open_dataset(\"/home/scratch/WRF_BCC/geography/geo_em.d01.nc\")\n",
    "ds = xr.open_mfdataset('/home/scratch/WRF_BCC/reflectivity/REFD/historical/1990-1991/*.nc')\n",
    "\n",
    "#merge the files and create needed infomation\n",
    "ds = xr.merge([ds, geog.squeeze()])\n",
    "ds = ds.rename({\"CLONG\": 'lon', 'CLAT': 'lat'})\n",
    "ds = ds.assign_coords({'x': ds.west_east, 'y': ds.south_north})\n",
    "ds = ds.assign_coords({'lon': ds.lon, 'lat': ds.lat})\n",
    "\n",
    "#set the lat-lon as the index\n",
    "ds.xoak.set_index(['lat', 'lon'], 'sklearn_geo_balltree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e9a895-740d-4a65-b7fe-c491363967bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load an USA shapefile\n",
    "usa = gpd.read_file(\"/home/jcorner1/Unidata/shapefiles/smoothing_econus.shp\")\n",
    "\n",
    "#mask the data out\n",
    "state_mask = regionmask.mask_geopandas(usa, ds.lon, ds.lat)\n",
    "ma = state_mask.values\n",
    "ma[~np.isnan(ma)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a244aa1-c1fb-4d5a-ac3b-068320ee2053",
   "metadata": {},
   "source": [
    "### Creating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6fed6c-be00-4af6-86ab-129c0d72c271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current year: 1990\n",
      "done thresholding! 1301508 potential storms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#iterate through each year (directory)\n",
    "for dirt_number in range(len(ref_dirts)):\n",
    "    \n",
    "    #open all the data within the directory\n",
    "    print(f'current year: {int(uh_dirts[dirt_number][-4:])-1}')\n",
    "    uh_ds = xr.open_mfdataset(f'{uh_dirts[dirt_number]}/*HELI_MAX*.nc')\n",
    "    ref_ds = xr.open_mfdataset(f'{ref_dirts[dirt_number]}/*.nc')\n",
    "    uvv_ds = xr.open_mfdataset(f'{uvv_dirts[dirt_number]}/*.nc')\n",
    "\n",
    "    #grab all values\n",
    "    uh_val = uh_ds.UP_HELI_MAX.values\n",
    "    refc_val = ref_ds.REFD.values\n",
    "    uvv_val = uvv_ds.W_UP_MAX.values\n",
    "    \n",
    "    #subset times\n",
    "    times = ref_ds.Time.values\n",
    "    \n",
    "    #threshold upward vertical velocities, reflectivity, and updraft helicity values. \n",
    "    thr_refc = ref_ds.where(refc_val >= 45.0, 0)\n",
    "    thr_uh = uh_ds.where(uh_val >= 65.0, 0)\n",
    "    thr_uvv = uvv_ds.where(uvv_val >= 18.0, 0)\n",
    "\n",
    "    thr_refc = thr_refc.where(thr_refc.REFD.values <= 45.0, 1)\n",
    "    thr_uh = thr_uh.where(thr_uh.UP_HELI_MAX.values <= 65.0, 1)\n",
    "    thr_uvv = thr_uvv.where(thr_uvv.W_UP_MAX.values <= 18.0, 1)\n",
    "    \n",
    "    #Give all areas with a UH of 75+ and reflectivity of 50+ a value of 1. \n",
    "    thr_val = thr_refc.REFD.values + thr_uh.UP_HELI_MAX.values + thr_uvv.W_UP_MAX.values *ma\n",
    "    \n",
    "    \n",
    "    #find locations where the value is 1.\n",
    "    locations = np.where(thr_val >= 1)\n",
    "    print(f'done thresholding! {len(locations[0])} potential storms')\n",
    "    \n",
    "    #close files\n",
    "    thr_refc.close()\n",
    "    thr_uh.close()\n",
    "    thr_uvv.close()\n",
    "    \n",
    "    uvv_ds.close()\n",
    "    uh_ds.close()\n",
    "    ref_ds.close()\n",
    "    \n",
    "    #create pandas dataframe\n",
    "    df = pd.DataFrame(columns=['x', 'y', 'Time', 'DBZ', 'UH', 'UVV'])\n",
    "\n",
    "    #iterate through all potential center points. \n",
    "    for point in range(len(locations[0])):\n",
    "\n",
    "        #save important attribute values for center points\n",
    "        time = locations[0][point]\n",
    "        y = locations[1][point] \n",
    "        x = locations[2][point]\n",
    "        \n",
    "        #add lines to the pandas dataframe\n",
    "        str_time = np.datetime_as_string(times[time])\n",
    "        df = df.append({'x': x, 'y':y, 'Time':str_time, 'DBZ': refc_val[time,y,x], \n",
    "                        'UH': uh_val[time,y,x], 'UVV':uvv_val[time,y,x]}, ignore_index=True)\n",
    "\n",
    "    #Save the dataframe as the csv.\n",
    "    df.to_csv(f'/home/scratch/jcorner1/syn_sev/dataframes/HIST{str_time[:4]}_threshold_dataframe.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb16eb95-04fc-4604-ae44-58ce603852bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>Time</th>\n",
       "      <th>DBZ</th>\n",
       "      <th>UH</th>\n",
       "      <th>UVV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1140</td>\n",
       "      <td>73</td>\n",
       "      <td>1990-10-01T14:00:00.000000000</td>\n",
       "      <td>50.860573</td>\n",
       "      <td>2.397167</td>\n",
       "      <td>8.330307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1153</td>\n",
       "      <td>81</td>\n",
       "      <td>1990-10-01T14:00:00.000000000</td>\n",
       "      <td>45.065521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.568310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1154</td>\n",
       "      <td>81</td>\n",
       "      <td>1990-10-01T14:00:00.000000000</td>\n",
       "      <td>47.343262</td>\n",
       "      <td>2.551833</td>\n",
       "      <td>8.987237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1153</td>\n",
       "      <td>82</td>\n",
       "      <td>1990-10-01T14:00:00.000000000</td>\n",
       "      <td>45.735554</td>\n",
       "      <td>1.073779</td>\n",
       "      <td>1.898480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1154</td>\n",
       "      <td>82</td>\n",
       "      <td>1990-10-01T14:00:00.000000000</td>\n",
       "      <td>45.186157</td>\n",
       "      <td>2.671107</td>\n",
       "      <td>6.963893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106796</th>\n",
       "      <td>760</td>\n",
       "      <td>428</td>\n",
       "      <td>1991-07-31T21:00:00.000000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.926620</td>\n",
       "      <td>18.176605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106797</th>\n",
       "      <td>761</td>\n",
       "      <td>428</td>\n",
       "      <td>1991-07-31T21:00:00.000000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.562691</td>\n",
       "      <td>18.034298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106798</th>\n",
       "      <td>762</td>\n",
       "      <td>428</td>\n",
       "      <td>1991-07-31T21:00:00.000000000</td>\n",
       "      <td>1.398526</td>\n",
       "      <td>36.828747</td>\n",
       "      <td>18.078941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106799</th>\n",
       "      <td>764</td>\n",
       "      <td>428</td>\n",
       "      <td>1991-07-31T21:00:00.000000000</td>\n",
       "      <td>54.610672</td>\n",
       "      <td>35.006802</td>\n",
       "      <td>17.834536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106800</th>\n",
       "      <td>765</td>\n",
       "      <td>428</td>\n",
       "      <td>1991-07-31T21:00:00.000000000</td>\n",
       "      <td>51.588570</td>\n",
       "      <td>35.670582</td>\n",
       "      <td>18.378044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1106801 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x    y                           Time        DBZ         UH  \\\n",
       "0        1140   73  1990-10-01T14:00:00.000000000  50.860573   2.397167   \n",
       "1        1153   81  1990-10-01T14:00:00.000000000  45.065521   0.000000   \n",
       "2        1154   81  1990-10-01T14:00:00.000000000  47.343262   2.551833   \n",
       "3        1153   82  1990-10-01T14:00:00.000000000  45.735554   1.073779   \n",
       "4        1154   82  1990-10-01T14:00:00.000000000  45.186157   2.671107   \n",
       "...       ...  ...                            ...        ...        ...   \n",
       "1106796   760  428  1991-07-31T21:00:00.000000000   0.000000  38.926620   \n",
       "1106797   761  428  1991-07-31T21:00:00.000000000   0.000000  38.562691   \n",
       "1106798   762  428  1991-07-31T21:00:00.000000000   1.398526  36.828747   \n",
       "1106799   764  428  1991-07-31T21:00:00.000000000  54.610672  35.006802   \n",
       "1106800   765  428  1991-07-31T21:00:00.000000000  51.588570  35.670582   \n",
       "\n",
       "               UVV  \n",
       "0         8.330307  \n",
       "1         2.568310  \n",
       "2         8.987237  \n",
       "3         1.898480  \n",
       "4         6.963893  \n",
       "...            ...  \n",
       "1106796  18.176605  \n",
       "1106797  18.034298  \n",
       "1106798  18.078941  \n",
       "1106799  17.834536  \n",
       "1106800  18.378044  \n",
       "\n",
       "[1106801 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67fd181-e284-4f66-b144-ab1d647f4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704592f4-e5f9-4e50-8dd3-b664cc2b4334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyEAE]",
   "language": "python",
   "name": "conda-env-pyEAE-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
